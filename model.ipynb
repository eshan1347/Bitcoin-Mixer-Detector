{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-01-08T17:59:14.039312Z","iopub.status.busy":"2025-01-08T17:59:14.038989Z","iopub.status.idle":"2025-01-08T17:59:19.167857Z","shell.execute_reply":"2025-01-08T17:59:19.166689Z","shell.execute_reply.started":"2025-01-08T17:59:14.039279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/mixer_lstm/pytorch/default/1/mixer_lstm.pt\n","/kaggle/input/mixer-ds/train_subset/train_subset.jl\n","/kaggle/input/mixer-ds/dev_subset/dev_subset.jl\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import json\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import time\n","import random\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support\n","import sklearn.metrics\n","from warnings import filterwarnings\n","from sklearn.metrics import accuracy_score\n","filterwarnings('ignore') \n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:03:09.541268Z","iopub.status.busy":"2025-01-08T18:03:09.540145Z","iopub.status.idle":"2025-01-08T18:04:36.566363Z","shell.execute_reply":"2025-01-08T18:04:36.565310Z","shell.execute_reply.started":"2025-01-08T18:03:09.541219Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["50001it [01:27, 574.65it/s]\n"]}],"source":["train_set = []\n","with open('/kaggle/input/mixer-ds/train_subset/train_subset.jl', 'r') as f:\n","    for l in tqdm(f):\n","        d = json.loads(l)\n","        train_set.append((d[0][1:], d[1][1:], d[2]))\n","dev_set = []"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:04:36.568877Z","iopub.status.busy":"2025-01-08T18:04:36.568414Z","iopub.status.idle":"2025-01-08T18:05:10.766142Z","shell.execute_reply":"2025-01-08T18:05:10.765104Z","shell.execute_reply.started":"2025-01-08T18:04:36.568830Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["21001it [00:34, 614.31it/s]\n"]}],"source":["with open('/kaggle/input/mixer-ds/dev_subset/dev_subset.jl', 'r') as f:\n","    for l in tqdm(f):\n","        d = json.loads(l)\n","        dev_set.append((d[0][1:], d[1][1:], d[2]))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:05:10.768256Z","iopub.status.busy":"2025-01-08T18:05:10.767908Z","iopub.status.idle":"2025-01-08T18:05:10.778894Z","shell.execute_reply":"2025-01-08T18:05:10.777802Z","shell.execute_reply.started":"2025-01-08T18:05:10.768223Z"},"trusted":true},"outputs":[],"source":["class TxDataSet(torch.utils.data.Dataset):\n","    def __init__(self, samples, max_len0=30, max_len1=10):\n","        self.samples = samples\n","        self.max_len0 = max_len0  \n","        self.max_len1 = max_len1\n","    \n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, index):\n","        sample = self.samples[index]\n","        t0 = sample[0]\n","        t1 = sample[1]\n","        label = sample[2]\n","        l0 = len(t0)\n","        l1 = len(t1)\n","        if l0 < self.max_len0:\n","            t0 += [[0] * 78 for _ in range(self.max_len0 - l0)]\n","        if l1 < self.max_len1:\n","            t1 += [[0] * 78 for _ in range(self.max_len1 - l1)]\n","        return l0, t0, l1, t1, label, index\n","\n","def collate_fx(batch):\n","    l0 = [b[0] for b in batch]\n","    t0 = torch.tensor([b[1] for b in batch], dtype=torch.float32)\n","    l1 = [b[2] for b in batch]\n","    t1 = torch.tensor([b[3] for b in batch], dtype=torch.float32)\n","    label = torch.tensor([b[4] for b in batch] , dtype=torch.float32)\n","    index = [b[5] for b in batch]\n","    return l0, t0, l1, t1, label, index"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:05:13.939518Z","iopub.status.busy":"2025-01-08T18:05:13.939102Z","iopub.status.idle":"2025-01-08T18:05:13.948630Z","shell.execute_reply":"2025-01-08T18:05:13.947339Z","shell.execute_reply.started":"2025-01-08T18:05:13.939483Z"},"trusted":true},"outputs":[],"source":["class DoubleLSTMClassify(nn.Module):\n","    def __init__(self, embedding_dim=78, hidden_dim=256):\n","        super(DoubleLSTMClassify, self).__init__()\n","        self.hidden_dim = hidden_dim\n","#         self.embedding = nn.Embedding(word_size, embedding_dim)\n","#         self.embedding.from_pretrained(torch.FloatTensor(vec))\n","        self.lstm0 = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=3, bidirectional=True, batch_first=True)\n","        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=3, bidirectional=True, batch_first=True)\n","        self.cls = nn.Linear(hidden_dim*2, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","        \n","    def forward(self, l0, t0, l1, t1):\n","        batch_size = t0.shape[0]\n","#         b1 = self.embedding(s1)\n","#         b2 = self.embedding(s2)\n","        k0 = self.lstm0(t0)[0]\n","        k1 = self.lstm1(t1)[0]\n","        x = torch.zeros(batch_size, self.hidden_dim*2).to(device)\n","        for i in range(batch_size):\n","            x[i][:self.hidden_dim] = k0[i][l0[i]-1]\n","            x[i][self.hidden_dim:] = k1[i][l1[i]-1]\n","        x = self.cls(x)\n","        x = self.sigmoid(x)\n","        return x"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:13:06.039877Z","iopub.status.busy":"2025-01-08T18:13:06.039472Z","iopub.status.idle":"2025-01-08T18:13:06.073051Z","shell.execute_reply":"2025-01-08T18:13:06.071892Z","shell.execute_reply.started":"2025-01-08T18:13:06.039842Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","max_len0 = 30\n","max_len1 = 10\n","batch_size = 512\n","data_workers = 0\n","\n","model = DoubleLSTMClassify(78)\n","model.to(device)\n","\n","learning_rate = 1e-3\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n","patience = 5\n","loss_list = []\n","epochs = 10\n","criterion = nn.BCELoss()\n","train_dataset = TxDataSet(train_set)\n","train_data_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    shuffle = True,\n","    num_workers=data_workers,\n","    collate_fn=collate_fx,\n",")\n","\n","dev_dataset = TxDataSet(dev_set)\n","dev_data_loader = torch.utils.data.DataLoader(\n","    dev_dataset,\n","    batch_size=batch_size,\n","    shuffle = False,\n","    num_workers=data_workers,\n","    collate_fn=collate_fx,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T02:44:35.519613Z","iopub.status.busy":"2024-12-12T02:44:35.518670Z","iopub.status.idle":"2024-12-12T02:44:35.533406Z","shell.execute_reply":"2024-12-12T02:44:35.532007Z","shell.execute_reply.started":"2024-12-12T02:44:35.519562Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def train_lstm(model, train_data_loader, dev_data_loader, optimizer, scheduler, criterion, epochs, patience):\n","    count = 0\n","    best_loss = float('inf')\n","    loss_dict = {'best_train_loss': float('inf') , 'best_test_loss': float('inf') , 'best_acc' : 0 }\n","    for i in range(epochs):\n","        print('epoch', i)\n","        train_loss = 0\n","        optimizer.zero_grad()\n","        model.train()\n","        with tqdm(train_data_loader, unit='batch') as loopTr:\n","            for j,batch in enumerate(loopTr):\n","                l0, t0, l1, t1, label, index = batch\n","                t0 = t0.to(device)\n","                t1 = t1.to(device)\n","                label = label.to(device)\n","                pred = model(l0, t0, l1, t1)\n","                loss = criterion(pred.squeeze(1), label)\n","                train_loss += loss.item()\n","                loss.backward()\n","                optimizer.step()\n","                if j%10 == 0:\n","                    loopTr.set_postfix(loss=loss.item())\n","        train_loss /= len(train_data_loader)\n","        loss_dict['best_train_loss'] = min(train_loss, loss_dict['best_train_loss'])\n","        if i%5 == 0:\n","            model.eval()\n","            with torch.no_grad():\n","                test_loss = 0\n","                test_acc = 0\n","                with tqdm(dev_data_loader, unit='batch') as loopTs:\n","                    for j,batch in enumerate(loopTs):\n","                        l0, t0, l1, t1, label, index = batch\n","                        t0 = t0.to(device)\n","                        t1 = t1.to(device)\n","                        label = label.to(device)\n","                        pred = model(l0, t0, l1, t1)\n","                        loss = criterion(pred.squeeze(1), label)\n","                        test_loss += loss.item()\n","                        test_acc += accuracy_score(label.cpu() , torch.round(pred).cpu())\n","                        if j%10 == 0:\n","                            loopTr.set_postfix(loss=loss.item())\n","            test_loss /= len(dev_data_loader)\n","            test_acc /= len(dev_data_loader)\n","            # print(f\"Epoch {i + 1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n","            best_loss = min(best_loss, test_loss)\n","            loss_dict['best_test_loss'] = best_loss\n","            loss_dict['best_acc'] = max(test_acc , loss_dict['best_acc'])\n","            if test_loss > best_loss:\n","                count += 1\n","            if count >= patience:\n","                print(f'Exited on {i+1} epoch')\n","                break\n","        scheduler.step(test_loss)\n","    return model, loss_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-07T17:18:37.280350Z","iopub.status.busy":"2024-12-07T17:18:37.279386Z","iopub.status.idle":"2024-12-07T21:40:33.683555Z","shell.execute_reply":"2024-12-07T21:40:33.682612Z","shell.execute_reply.started":"2024-12-07T17:18:37.280313Z"},"trusted":true},"outputs":[],"source":["model, loss_dict = train_lstm(model, train_data_loader, dev_data_loader, optimizer, scheduler, criterion, 500, patience)\n","torch.save(model.state_dict(), '/kaggle/working/mixer_lstm.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T09:51:11.238629Z","iopub.status.busy":"2024-12-12T09:51:11.237989Z","iopub.status.idle":"2024-12-12T09:51:11.523877Z","shell.execute_reply":"2024-12-12T09:51:11.522727Z","shell.execute_reply.started":"2024-12-12T09:51:11.238584Z"},"trusted":true},"outputs":[],"source":["model.load_state_dict(torch.load('/kaggle/input/mixer_lstm/pytorch/default/1/mixer_lstm.pt',map_location='cpu', weights_only=False))"]},{"cell_type":"markdown","metadata":{},"source":["## Model Evaluation & Visualization"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:13:12.242803Z","iopub.status.busy":"2025-01-08T18:13:12.242353Z","iopub.status.idle":"2025-01-08T18:13:48.979585Z","shell.execute_reply":"2025-01-08T18:13:48.978341Z","shell.execute_reply.started":"2025-01-08T18:13:12.242767Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 42/42 [00:36<00:00,  1.14batch/s]\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","    test_loss = 0\n","    test_acc = 0\n","    with tqdm(dev_data_loader, unit='batch') as loopTs:\n","        for j,batch in enumerate(loopTs):\n","            l0, t0, l1, t1, label, index = batch\n","            t0 = t0.to(device)\n","            t1 = t1.to(device)\n","            label = label.to(device)\n","            pred = model(l0, t0, l1, t1)\n","            loss = criterion(pred.squeeze(1), label)\n","            test_loss += loss.item()\n","            test_acc += accuracy_score(label.cpu() , torch.round(pred).cpu())\n","test_loss /= len(dev_data_loader)\n","test_acc /= len(dev_data_loader)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:24:52.889560Z","iopub.status.busy":"2025-01-08T18:24:52.889104Z","iopub.status.idle":"2025-01-08T18:24:52.897240Z","shell.execute_reply":"2025-01-08T18:24:52.895886Z","shell.execute_reply.started":"2025-01-08T18:24:52.889522Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(0.6933349598021734, 0.4982122189153439)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["test_loss , test_acc"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:24:24.906902Z","iopub.status.busy":"2025-01-08T18:24:24.906502Z","iopub.status.idle":"2025-01-08T18:24:24.917931Z","shell.execute_reply":"2025-01-08T18:24:24.916737Z","shell.execute_reply.started":"2025-01-08T18:24:24.906870Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import (\n","    confusion_matrix,      # To calculate the confusion matrix\n","    balanced_accuracy_score,  # To calculate balanced accuracy\n","    accuracy_score,         # To calculate overall accuracy\n","    precision_score,        # To calculate precision (macro and binary)\n","    recall_score,           # To calculate recall (macro and binary)\n","    f1_score,               # To calculate F1-score (macro and binary)\n","    roc_auc_score,          # To calculate the Area Under the ROC Curve (AUC-ROC)\n","    roc_curve,              # To generate the ROC curve (false positive vs. true positive rates)\n","    precision_recall_curve  # To generate Precision-Recall curves\n",")\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","\n","def evaluate(actual, predicted):\n","    eval_metric = {}\n","    eval_metric['conf_matrix'] = confusion_matrix(actual, predicted)\n","    \n","    eval_metric['balanced_accuracy'] = round(balanced_accuracy_score(actual, predicted),7)\n","    eval_metric['accuracy'] = round(accuracy_score(actual, predicted),7)\n","    \n","    eval_metric['macro_precision'] = round(precision_score(actual, predicted, average=\"macro\"),7)\n","    eval_metric['macro_recall'] = round(recall_score(actual,predicted, average=\"macro\"),7)\n","    eval_metric['macro_f1'] = round(f1_score(actual,predicted, average=\"macro\"),7)\n","    eval_metric['macro_roc'] = round(roc_auc_score(actual, predicted, average=\"macro\"),7)\n","\n","    eval_metric['precision'] = round(precision_score(actual, predicted),7)\n","    eval_metric['recall'] = round(recall_score(actual,predicted),7)\n","    eval_metric['f1'] = round(f1_score(actual,predicted),7)\n","    eval_metric['roc'] = round(roc_auc_score(actual, predicted),7)\n","\n","    false_pos_rate, true_pos_rate, thresholds = roc_curve(actual, predicted)\n","    eval_metric['false_pos_rate'] = false_pos_rate\n","    eval_metric['true_pos_rate'] = true_pos_rate\n","    eval_metric['thresholds'] = thresholds\n","    \n","    precision_rt, recall_rt, threshold_rt = precision_recall_curve(actual, predicted)\n","    eval_metric['precision_rt'] = precision_rt\n","    eval_metric['recall_rt'] = recall_rt\n","    eval_metric['threshold_rt'] = threshold_rt\n","    return eval_metric"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:29:05.050062Z","iopub.status.busy":"2025-01-08T18:29:05.049550Z","iopub.status.idle":"2025-01-08T18:29:43.434296Z","shell.execute_reply":"2025-01-08T18:29:43.432899Z","shell.execute_reply.started":"2025-01-08T18:29:05.050019Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.4982122189153439"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# dev_data_loader = torch.utils.data.DataLoader(\n","#     dev_dataset,\n","#     batch_size=512,\n","#     shuffle = False,\n","#     num_workers=data_workers,\n","#     collate_fn=collate_fx,\n","# )\n","\n","acc = 0\n","\n","with torch.no_grad():\n","    for batch in dev_data_loader:\n","        l0, t0, l1, t1, label, index = batch\n","        t0 = torch.tensor(t0).to(device)\n","        t1 = torch.tensor(t1).to(device)\n","        label = torch.tensor(label).to(device)\n","        pred = model(l0, t0, l1, t1)\n","        pred_labels = (pred > 0.5).int()\n","        acc += accuracy_score(label, pred_labels)\n","acc /= len(dev_data_loader)\n","acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T02:50:20.727115Z","iopub.status.busy":"2024-12-12T02:50:20.726587Z","iopub.status.idle":"2024-12-12T02:50:20.734532Z","shell.execute_reply":"2024-12-12T02:50:20.733176Z","shell.execute_reply.started":"2024-12-12T02:50:20.727061Z"},"trusted":true},"outputs":[],"source":["label = dev_data_loader.dataset.tensor\n","pred = model(l0, t0, l1, t1)\n","pred_labels = (pred > 0.5).int()\n","eval_metric = evaluate(label, pred_labels)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2025-01-08T18:27:53.729682Z","iopub.status.busy":"2025-01-08T18:27:53.728075Z","iopub.status.idle":"2025-01-08T18:27:53.742337Z","shell.execute_reply":"2025-01-08T18:27:53.740618Z","shell.execute_reply.started":"2025-01-08T18:27:53.729602Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'conf_matrix': array([[258,   0],\n","        [254,   0]]),\n"," 'balanced_accuracy': 0.5,\n"," 'accuracy': 0.5039062,\n"," 'macro_precision': 0.2519531,\n"," 'macro_recall': 0.5,\n"," 'macro_f1': 0.3350649,\n"," 'macro_roc': 0.5,\n"," 'precision': 0.0,\n"," 'recall': 0.0,\n"," 'f1': 0.0,\n"," 'roc': 0.5,\n"," 'false_pos_rate': array([0., 1.]),\n"," 'true_pos_rate': array([0., 1.]),\n"," 'thresholds': array([1, 0], dtype=int32),\n"," 'precision_rt': array([0.49609375, 1.        ]),\n"," 'recall_rt': array([1., 0.]),\n"," 'threshold_rt': array([0], dtype=int32)}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["eval_metric"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T03:29:03.590298Z","iopub.status.busy":"2024-12-12T03:29:03.589877Z","iopub.status.idle":"2024-12-12T03:29:03.784316Z","shell.execute_reply":"2024-12-12T03:29:03.783068Z","shell.execute_reply.started":"2024-12-12T03:29:03.590260Z"},"trusted":true},"outputs":[],"source":["fpr, tpr, thresholds = metrics.roc_curve(label, pred_labels)\n","roc_auc = metrics.auc(fpr, tpr)\n","display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n","                                  estimator_name='lstm')\n","display.plot()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T03:55:54.127053Z","iopub.status.busy":"2024-12-12T03:55:54.124989Z","iopub.status.idle":"2024-12-12T03:55:54.436913Z","shell.execute_reply":"2024-12-12T03:55:54.435600Z","shell.execute_reply.started":"2024-12-12T03:55:54.126968Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","cm = confusion_matrix(label, pred_labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n","disp.plot(cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T03:59:02.628635Z","iopub.status.busy":"2024-12-12T03:59:02.627676Z","iopub.status.idle":"2024-12-12T03:59:02.860004Z","shell.execute_reply":"2024-12-12T03:59:02.858690Z","shell.execute_reply.started":"2024-12-12T03:59:02.628578Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","metrics = {'Accuracy': eval_metric['accuracy'], 'Precision': eval_metric['precision'], 'Recall': eval_metric['recall'], 'F1-Score': eval_metric['f1']}\n","\n","plt.bar(metrics.keys(), metrics.values(), color='skyblue')\n","plt.xlabel('Metrics')\n",".\n","plt.ylabel('Score')\n","plt.ylim(0, 1)\n","plt.title('Model Performance Metrics')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Transaction Tree Extraction & Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T09:38:41.599647Z","iopub.status.busy":"2024-12-12T09:38:41.599171Z","iopub.status.idle":"2024-12-12T09:38:41.624243Z","shell.execute_reply":"2024-12-12T09:38:41.622808Z","shell.execute_reply.started":"2024-12-12T09:38:41.599609Z"},"trusted":true},"outputs":[],"source":["tx_js = [\n","    {\n","    \"transaction\": [\n","      \"bbefefd2f5da927a570213c8e98418ebdff4deebf48726ceabdd1ea58655f654\"\n","    ],\n","    \"precursors\": [\n","      \"0d267f19bde7f50365dc05ae7d2c03e5d9dd3e382619199d45b86640cae6cd8b\"\n","    ]\n","  },\n","  {\n","    \"transaction\": [\n","      \"0d267f19bde7f50365dc05ae7d2c03e5d9dd3e382619199d45b86640cae6cd8b\"\n","    ],\n","    \"precursors\": [\n","      \"691a7e28f76b88001c0a59b06bdd5759271e4e86d9cfb9cef338ce9c4cc3d0bd\"\n","    ]\n","  },\n","  {\n","    \"transaction\": [\n","      \"691a7e28f76b88001c0a59b06bdd5759271e4e86d9cfb9cef338ce9c4cc3d0bd\"\n","    ],\n","    \"precursors\": [\n","      \"1d0d08eb74d1b44b780b0571aec3b88b1541d00b5ded359901179c4f08f65446\"\n","    ]\n","  },\n","  {\n","    \"transaction\": [\n","      \"1d0d08eb74d1b44b780b0571aec3b88b1541d00b5ded359901179c4f08f65446\"\n","    ],\n","    \"precursors\": [\n","      \"012e93365369509f47520f52c2bb7970d6149f62403954fe3a8686453144016d\",\n","      \"39e855dedacce4c14570cea5a42618eb634442e7070f8e3688220dff72ceaba9\",\n","      \"3ad529407ccced341ceb930faa41f23f8ec52b8e8d348d271120cab92d587286\",\n","      \"5b66155bb209af8b20bbd1903635a6add78416adbeb1b81f640050ccb9936032\",\n","      \"6cda1fec2ad02b1e1a551224c075c9c74492d8122371df067fd2afbfb22cbbb4\",\n","      \"a48b08265de541b01bcfd342e37d438530d48321d045e1c89e31801d5632879e\",\n","      \"9f8f5252d41bd2117df685c5b84bc47a65c91d4956b509834fc3c458b9e46236\",\n","      \"eadfc1caf90f15f44c12658e971bd9f7c908e988e2a4ce83059edec2372135b8\",\n","      \"20e8b3e4b0b945de4691cfa0a94f0ef325d1f39631f5d665807a48cd0612e92f\",\n","      \"72b6f28ab5bda67b4fe001746c050d3af484002ac596ec586864d535119bd07f\",\n","      \"b768e9836b547cefd99a8982fb5413840989fa97e3303afedac83a6ee9f19114\",\n","      \"83d92f183353755777fc97794fae534c615b265d427e833cff55c1765080914d\",\n","      \"ee1e842534964e57880b1a7b004a91553693312c6852a9885006a3f37da5bd5a\",\n","      \"6510580f4b6b0c9aa9f70b123fbdb91a21d160a8ce523468d1c5cdaa268f9757\",\n","      \"b85d6089f2270cc394e70e3425c5ae86dc08781c41ac05226c5f49fb159e4fe7\",\n","      \"8a8703a721e0faebdcb43c3180e84cc4f6c66d0a1f85047d84c3cbd2f24e6a13\",\n","      \"22e7a5d390159014afc0855033e6abc85f325296c814fb587a1f06af48d9dac8\",\n","      \"d016fe27300966634165d4867efe92f9dab60dcd3bca477513a0d86bceb49570\",\n","      \"e2200252e8605602418ef36b077e7ecbcc9910cb0834e7a35162ce1b107fa007\"\n","    ]\n","  }\n","]\n","\n","# \"transaction_hash\":\n","# \"input_amount_sum\":\n","# \"output_amount_sum\": \n","# \"transaction_fee\":\n","# \"input_amount_std_dev\":\n","# \"output_amount_std_dev\":\n","# \"input_count_avg\":\n","# \"transaction_size\":\n","# \"avg_input_amount\":\n","# \"output_count_avg\":\n","# \"avg_output_amount\":\n","# \"input_address_count\":\n","# \"output_address_count\":\n","# \"transaction_weight\":\n","# \"lock_time\":\n","# \"is_coinbase\":\n","\n","tx_features = {\n","'bbefefd2f5da927a570213c8e98418ebdff4deebf48726ceabdd1ea58655f654':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 4000000000, 1000000000, 2, 1500000000.0, 2500000000.0, 2],\n","'0d267f19bde7f50365dc05ae7d2c03e5d9dd3e382619199d45b86640cae6cd8b':[2500000000, 2500000000, 0, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 1, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 2],\n","'691a7e28f76b88001c0a59b06bdd5759271e4e86d9cfb9cef338ce9c4cc3d0bd':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 2500000000, 2500000000, 2, 0.0, 2500000000.0, 2],\n","'1d0d08eb74d1b44b780b0571aec3b88b1541d00b5ded359901179c4f08f65446':[10000000000, 10000000000, 0, 5000000000, 5000000000, 2, 0.0, 5000000000.0, 2, 10000000000, 10000000000, 1, 0.0, 10000000000.0, 1],\n","'012e93365369509f47520f52c2bb7970d6149f62403954fe3a8686453144016d':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1],\n","'39e855dedacce4c14570cea5a42618eb634442e7070f8e3688220dff72ceaba9':[27500000000, 27500000000, 0, 5000000000, 2500000000, 6, 931694990.6249125, 4583333333.333333, 6, 27500000000, 27500000000, 1, 0.0, 27500000000.0, 1],\n","'3ad529407ccced341ceb930faa41f23f8ec52b8e8d348d271120cab92d587286':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1],\n","'5b66155bb209af8b20bbd1903635a6add78416adbeb1b81f640050ccb9936032':[27500000000, 27500000000, 0, 5000000000, 2500000000, 6, 931694990.6249125, 4583333333.333333, 6, 27500000000, 27500000000, 1, 0.0, 27500000000.0, 1],\n","'6cda1fec2ad02b1e1a551224c075c9c74492d8122371df067fd2afbfb22cbbb4':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 4000000000, 1000000000, 2, 1500000000.0, 2500000000.0, 2],\n","'a48b08265de541b01bcfd342e37d438530d48321d045e1c89e31801d5632879e':[2500000000, 2500000000, 0, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 1, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 2],\n","'9f8f5252d41bd2117df685c5b84bc47a65c91d4956b509834fc3c458b9e46236':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 2500000000, 2500000000, 2, 0.0, 2500000000.0, 2],\n","'eadfc1caf90f15f44c12658e971bd9f7c908e988e2a4ce83059edec2372135b8':[10000000000, 10000000000, 0, 5000000000, 5000000000, 2, 0.0, 5000000000.0, 2, 10000000000, 10000000000, 1, 0.0, 10000000000.0, 1],\n","'20e8b3e4b0b945de4691cfa0a94f0ef325d1f39631f5d665807a48cd0612e92f':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1],\n","'72b6f28ab5bda67b4fe001746c050d3af484002ac596ec586864d535119bd07f':[27500000000, 27500000000, 0, 5000000000, 2500000000, 6, 931694990.6249125, 4583333333.333333, 6, 27500000000, 27500000000, 1, 0.0, 27500000000.0, 1],\n","'b768e9836b547cefd99a8982fb5413840989fa97e3303afedac83a6ee9f19114':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1],\n","'83d92f183353755777fc97794fae534c615b265d427e833cff55c1765080914d':[27500000000, 27500000000, 0, 5000000000, 2500000000, 6, 931694990.6249125, 4583333333.333333, 6, 27500000000, 27500000000, 1, 0.0, 27500000000.0, 1],\n","'ee1e842534964e57880b1a7b004a91553693312c6852a9885006a3f37da5bd5a':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 4000000000, 1000000000, 2, 1500000000.0, 2500000000.0, 2],\n","'6510580f4b6b0c9aa9f70b123fbdb91a21d160a8ce523468d1c5cdaa268f9757':[2500000000, 2500000000, 0, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 1, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 2],\n","'b85d6089f2270cc394e70e3425c5ae86dc08781c41ac05226c5f49fb159e4fe7':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 2500000000, 2500000000, 2, 0.0, 2500000000.0, 2],\n","'8a8703a721e0faebdcb43c3180e84cc4f6c66d0a1f85047d84c3cbd2f24e6a13':[10000000000, 10000000000, 0, 5000000000, 5000000000, 2, 0.0, 5000000000.0, 2, 10000000000, 10000000000, 1, 0.0, 10000000000.0, 1],\n","'22e7a5d390159014afc0855033e6abc85f325296c814fb587a1f06af48d9dac8':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1],\n","'d016fe27300966634165d4867efe92f9dab60dcd3bca477513a0d86bceb49570':[27500000000, 27500000000, 0, 5000000000, 2500000000, 6, 931694990.6249125, 4583333333.333333, 6, 27500000000, 27500000000, 1, 0.0, 27500000000.0, 1],\n","'e2200252e8605602418ef36b077e7ecbcc9910cb0834e7a35162ce1b107fa007':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T09:39:25.506003Z","iopub.status.busy":"2024-12-12T09:39:25.505534Z","iopub.status.idle":"2024-12-12T09:39:25.513076Z","shell.execute_reply":"2024-12-12T09:39:25.511807Z","shell.execute_reply.started":"2024-12-12T09:39:25.505964Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import json\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import time\n","import random\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support\n","import sklearn.metrics\n","from warnings import filterwarnings\n","from sklearn.metrics import accuracy_score\n","from collections import defaultdict, deque"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T09:47:31.982496Z","iopub.status.busy":"2024-12-12T09:47:31.982058Z","iopub.status.idle":"2024-12-12T09:47:32.000639Z","shell.execute_reply":"2024-12-12T09:47:31.998740Z","shell.execute_reply.started":"2024-12-12T09:47:31.982460Z"},"trusted":true},"outputs":[],"source":["tree = defaultdict(list)\n","for item in tx_js:\n","    tx = item['transaction'][0]\n","    for precursor in item['precursors']:\n","        tree[precursor].append(tx)\n","\n","root = [k for k in tree.keys() if k not in [item[\"transaction\"][0] for item in tx_js]][0]\n","queue = deque([(root, 0)])  # (transaction, level)\n","level_features = defaultdict(lambda: defaultdict(list))\n","\n","while queue:\n","    node, level = queue.popleft()\n","    features = tx_features[node]\n","    for i, feature in enumerate(features):\n","        level_features[level][i].append(feature)\n","    for child in tree[node]:\n","        queue.append((child, level + 1))\n","\n","# level_stats = defaultdict(dict)\n","# for level, feature_dict in level_features.items():\n","#     for feature_idx, values in feature_dict.items():\n","#         values = np.array(values)\n","#         level_stats[level][f\"Feature_{feature_idx}_Sum\"] = np.sum(values)\n","#         level_stats[level][f\"Feature_{feature_idx}_Max\"] = np.max(values)\n","#         level_stats[level][f\"Feature_{feature_idx}_Min\"] = np.min(values)\n","#         level_stats[level][f\"Feature_{feature_idx}_Std\"] = np.std(values)\n","#         level_stats[level][f\"Feature_{feature_idx}_Avg\"] = np.mean(values)\n","\n","# total_transactions = len(tx_features)\n","\n","level_stats_succ = defaultdict(list)\n","for level, feature_dict in level_features.items():\n","    # Add total transactions at this level\n","    total_transactions = len(feature_dict[0])  # All features will have the same number of entries\n","    level_stats = [total_transactions, 0, total_transactions]\n","    \n","    # Compute statistics for each feature\n","    for feature_idx, values in feature_dict.items():\n","        values = np.array(values)\n","        level_stats.extend([\n","            np.sum(values),\n","            np.max(values),\n","            np.min(values),\n","            np.std(values),\n","            np.mean(values)\n","        ])\n","    \n","    # Ensure we have 76 values: 1 (total) + 15 features * 5 stats\n","    assert len(level_stats) == 78\n","    level_stats_succ[level] = level_stats\n","\n","stats_list = []\n","for i,j in level_stats_succ.items():\n","    stats_list.append(j)\n","# stats_list = [total_transactions, 0, total_transactions]\n","# for level in level_stats.keys():\n","#     for key in feature_dict.keys():\n","#         stats_list.append(level_stats[level][key])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T09:50:28.415816Z","iopub.status.busy":"2024-12-12T09:50:28.415377Z","iopub.status.idle":"2024-12-12T09:50:28.427134Z","shell.execute_reply":"2024-12-12T09:50:28.425589Z","shell.execute_reply.started":"2024-12-12T09:50:28.415778Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# Generate Successor tree levels \n","\n","tx_js = [\n","  {\n","    \"transaction\": \"549dddd80fb5203e63e057a2139ce9d00357f94b59c7ed8778c5e1f1aa953db9\",\n","    \"successors\": [\n","      \"4eb717c3e79d70dea15c2cb5cf8470f271244bea2dac7f9ec1789ad4feec4054\",\n","      \"8ea778e48f24f879408b3f0facbb49cd91d93b07119eba76f3c28a2efa65eceb\",\n","      \"a38d8f2466951dc96cf7bb6a27401b25ecba78b04b1bb063ab2237f11ae7af8b\",\n","      \"018a9b136b018779ff205584cc008105cd0c4f72f0e7d92acf2ecb1b5cd83a14\"\n","    ]\n","  },\n","  {\n","    \"transaction\": \"018a9b136b018779ff205584cc008105cd0c4f72f0e7d92acf2ecb1b5cd83a14\",\n","    \"successors\": [\n","      \"d2030383e96bfb12049ff2c3dead03d58863426dba8bd4a712aff4b95e062453\"\n","    ]\n","  },\n","  {\n","    \"transaction\": \"d2030383e96bfb12049ff2c3dead03d58863426dba8bd4a712aff4b95e062453\",\n","    \"successors\": [\n","      \"cab8d5baf4ab79ce917e6f4035e155add1a15cad0be8eb8e30d845ba838fcedf\"\n","    ]\n","  }\n","]\n","\n","tx_features = {\n","'549dddd80fb5203e63e057a2139ce9d00357f94b59c7ed8778c5e1f1aa953db9':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 4000000000, 1000000000, 2, 1500000000.0, 2500000000.0, 2],\n","'4eb717c3e79d70dea15c2cb5cf8470f271244bea2dac7f9ec1789ad4feec4054':[2500000000, 2500000000, 0, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 1, 2400000000, 100000000, 2, 1150000000.0, 1250000000.0, 2],\n","'8ea778e48f24f879408b3f0facbb49cd91d93b07119eba76f3c28a2efa65eceb':[5000000000, 5000000000, 0, 5000000000, 5000000000, 1, 0.0, 5000000000.0, 1, 2500000000, 2500000000, 2, 0.0, 2500000000.0, 2],\n","'a38d8f2466951dc96cf7bb6a27401b25ecba78b04b1bb063ab2237f11ae7af8b':[10000000000, 10000000000, 0, 5000000000, 5000000000, 2, 0.0, 5000000000.0, 2, 10000000000, 10000000000, 1, 0.0, 10000000000.0, 1],\n","'018a9b136b018779ff205584cc008105cd0c4f72f0e7d92acf2ecb1b5cd83a14':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1],\n","'d2030383e96bfb12049ff2c3dead03d58863426dba8bd4a712aff4b95e062453':[27500000000, 27500000000, 0, 5000000000, 2500000000, 6, 931694990.6249125, 4583333333.333333, 6, 27500000000, 27500000000, 1, 0.0, 27500000000.0, 1],\n","'cab8d5baf4ab79ce917e6f4035e155add1a15cad0be8eb8e30d845ba838fcedf':[50000000000, 50000000000, 0, 5000000000, 5000000000, 10, 0.0, 5000000000.0, 10, 50000000000, 50000000000, 1, 0.0, 50000000000.0, 1],\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T09:50:39.469546Z","iopub.status.busy":"2024-12-12T09:50:39.468212Z","iopub.status.idle":"2024-12-12T09:50:39.485673Z","shell.execute_reply":"2024-12-12T09:50:39.484139Z","shell.execute_reply.started":"2024-12-12T09:50:39.469497Z"},"trusted":true},"outputs":[],"source":["tree = defaultdict(list)\n","for item in tx_js:\n","    tx = item['transaction']\n","    for successor in item['successors']:\n","        tree[tx].append(successor)\n","\n","all_successors = {s for item in tx_js for s in item[\"successors\"]}\n","root = next(t for t in tree if t not in all_successors)\n","queue = deque([(root, 0)])  # (transaction, level)\n","level_features = defaultdict(lambda: defaultdict(list))\n","\n","while queue:\n","    node, level = queue.popleft()\n","    features = tx_features[node]\n","    for i, feature in enumerate(features):\n","        level_features[level][i].append(feature)\n","    for child in tree[node]:\n","        queue.append((child, level + 1))\n","\n","level_stats_succ = defaultdict(list)\n","for level, feature_dict in level_features.items():\n","    # Add total transactions at this level\n","    total_transactions = len(feature_dict[0])  # All features will have the same number of entries\n","    level_stats = [total_transactions, 0, total_transactions]\n","    \n","    # Compute statistics for each feature\n","    for feature_idx, values in feature_dict.items():\n","        values = np.array(values)\n","        level_stats.extend([\n","            np.sum(values),\n","            np.max(values),\n","            np.min(values),\n","            np.std(values),\n","            np.mean(values)\n","        ])\n","    \n","    # Ensure we have 76 values: 1 (total) + 15 features * 5 stats\n","    assert len(level_stats) == 78\n","    level_stats_succ[level] = level_stats\n","\n","stats_list_succ = []\n","for i,j in level_stats_succ.items():\n","    stats_list_succ.append(j)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-12T09:53:42.095318Z","iopub.status.busy":"2024-12-12T09:53:42.094665Z","iopub.status.idle":"2024-12-12T09:53:42.150990Z","shell.execute_reply":"2024-12-12T09:53:42.149639Z","shell.execute_reply.started":"2024-12-12T09:53:42.095254Z"},"trusted":true},"outputs":[],"source":["test_set = [(stats_list, stats_list_succ, 0)]\n","# print(level_stats)\n","test_dataset = TxDataSet(test_set)\n","for batch in test_dataset:\n","    l0, t0, l1, t1, label, index = batch\n","    t0 = torch.tensor(t0).unsqueeze(dim=0).to(device).type(torch.float32)\n","    t1 = torch.tensor(t1).unsqueeze(dim=0).to(device).type(torch.float32)\n","    label = torch.tensor(label).unsqueeze(dim=0).to(device).type(torch.float32)\n","    pred = model([l0], t0, [l1], t1)\n","    pred_labels = (pred > 0.5).int()\n","\n","print(f'Prediction : {pred_labels}')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6249599,"sourceId":10127206,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":189195,"modelInstanceId":166873,"sourceId":195711,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30804,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
